{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import konlpy\n",
    "import csv\n",
    "from konlpy.tag import Okt as Twitter\n",
    "from pprint import pprint\n",
    "twitter_pos_tagger = Twitter()\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import CoherenceModel\n",
    "def token_combine(doc):\n",
    "    return ['/'.join(t) for t in twitter_pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "perplexity_score = []\n",
    "coherence_score = []\n",
    "for i in range(2,20) :\n",
    "    clear_output(wait=True)\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=i, id2word = dictionary, passes=50)\n",
    "    perplexity_score.append(ldamodel.log_perplexity(doc_term_matrix))\n",
    "    coherence_score.append(CoherenceModel(model=ldamodel, texts=corpus, dictionary=dictionary, coherence='c_v').get_coherence())\n",
    "    print(i, 'th process complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity Scores\n",
    "plt.plot(range(2,8),perplexity_score[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coherence Scores\n",
    "plt.plot(range(2,8),coherence_score[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "pprint(ldamodel.print_topics(num_words=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics = ldamodel[doc_term_matrix]\n",
    "lda_topics[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "scores = list(chain(*[[score for topic_id,score in topic] \\\n",
    "                      for topic in [doc for doc in lda_topics]]))\n",
    "threshold = sum(scores)/len(scores)\n",
    "print (threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_lists = []\n",
    "j_lists = []\n",
    "for i, j in zip(lda_topics, corpus) :\n",
    "    i_lists.append(i)\n",
    "    j_lists.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_lists[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 in i_lists[6][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
